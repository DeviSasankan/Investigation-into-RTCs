# -*- coding: utf-8 -*-
"""Investigation into RTCs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T-Nggoge9MsHnqbxXIvriZMncnsKC4-m
"""

print ('Hello World')

from google.colab import drive

drive.mount ('/content/gdrive')

"""# **Reading Datasets**"""

import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
plt.style.use('ggplot')
pd.set_option("display.max_columns", 100)

# Read the datasets

import pandas as pd

dfaccident = pd.read_csv('/content/gdrive/MyDrive/RTC dataset/dft-road-casualty-statistics-accident-2021.csv')
dfcasuality = pd.read_csv('/content/gdrive/MyDrive/RTC dataset/dft-road-casualty-statistics-casualty-2021.csv')
dfvehicle = pd.read_csv('/content/gdrive/MyDrive/RTC dataset/dft-road-casualty-statistics-vehicle-2021.csv')

"""# **Data Preprocessing**"""

# Visualize the Accident dataset

dfaccident

# Data Preprocessing of the first dataset accident
# Remove columns not relevant to the study

dfaccident.drop(columns=['accident_year','accident_reference','location_easting_osgr','location_northing_osgr','longitude','latitude',
                         'police_force','local_authority_district','local_authority_ons_district','local_authority_highway','first_road_number',
                         'junction_detail','junction_control','second_road_number','special_conditions_at_site',
                         'did_police_officer_attend_scene_of_accident','lsoa_of_accident_location'], inplace=True)

# Get the number of rows and columns

dfaccident.shape

# Changing any missing value to handle it with pandas better, it will be replaced to NaN:

import numpy as np

def missing_values_change(val):
    if str(val)=='9' or str(val)=='-1' or str(val)=="Unknown" or str(val)=='99':
        return np.nan
    else:
        return val
for col in dfaccident.columns:
    dfaccident[col] = dfaccident[col].apply(lambda x:missing_values_change(x))

# Checking missing values percentage
result=dfaccident.isnull().mean()*100
result=result.round(1)
print(result)

dfaccident.isnull().sum().sum()

# Replace missing values using mean

dfaccident["second_road_class"].replace(np.NaN,dfaccident["second_road_class"].mean(),inplace=True)
dfaccident["pedestrian_crossing_human_control"].replace(np.NaN,dfaccident["pedestrian_crossing_human_control"].mean(),inplace=True)
dfaccident["pedestrian_crossing_physical_facilities"].replace(np.NaN,dfaccident["pedestrian_crossing_physical_facilities"].mean(),inplace=True)
dfaccident["light_conditions"].replace(np.NaN,dfaccident["light_conditions"].mean(),inplace=True)
dfaccident["weather_conditions"].replace(np.NaN,dfaccident["weather_conditions"].mean(),inplace=True)
dfaccident["road_surface_conditions"].replace(np.NaN,dfaccident["road_surface_conditions"].mean(),inplace=True)
dfaccident["carriageway_hazards"].replace(np.NaN,dfaccident["carriageway_hazards"].mean(),inplace=True)
dfaccident["trunk_road_flag"].replace(np.NaN,dfaccident["trunk_road_flag"].mean(),inplace=True)
dfaccident["road_type"].replace(np.NaN,dfaccident["road_type"].mean(),inplace=True)

result=dfaccident.isnull().mean()*100
result=result.round(1)
print(result)

# Visualize the Casuality dataset

dfcasuality

# Data Preprocessing of the second dataset casuality
# Remove columns not relevant to the study

dfcasuality.drop(columns=['accident_year','accident_reference','vehicle_reference','casualty_reference','casualty_severity',
                          'pedestrian_location','pedestrian_movement','car_passenger','bus_or_coach_passenger','pedestrian_road_maintenance_worker',
                          'casualty_type','casualty_home_area_type','casualty_imd_decile','lsoa_of_casualty'],inplace=True)

# Get the number of rows and columns

dfcasuality.shape

# Changing any missing value to handle it with pandas better, it will be replaced to NaN:

def missing_values_change(val):
    if str(val)=='9' or str(val)=='-1' or str(val)=="Unknown" or str(val)=='99':
        return np.nan
    else:
        return val
for col in dfcasuality.columns:
    dfcasuality[col] = dfcasuality[col].apply(lambda x:missing_values_change(x))

# Checking missing values percentage

dfcasuality.isnull().mean()*100

dfcasuality.isnull().sum().sum()

dfcasuality

dfcasuality1 = dfcasuality.fillna(method='pad')
dfcasuality1

# Replace missing values using mean

dfcasuality["sex_of_casualty"].replace(np.NaN,dfcasuality["sex_of_casualty"].mean(),inplace=True)
dfcasuality["age_of_casualty"].replace(np.NaN,dfcasuality["age_of_casualty"].mean(),inplace=True)
dfcasuality["age_band_of_casualty"].replace(np.NaN,dfcasuality["age_band_of_casualty"].mean(),inplace=True)

dfcasuality.isnull().mean()*100

# Visualize the Vehicle dataset

dfvehicle

# Data Preprocessing of the Third dataset vehicle
# Remove columns not relevant to the study

dfvehicle.drop(columns=['accident_year','accident_reference','vehicle_reference','vehicle_direction_from','vehicle_direction_to',
                        'first_point_of_impact','driver_home_area_type','lsoa_of_driver'], inplace=True)

# Get the number of rows and columns

dfvehicle.shape

# Changing any missing value to handle it with pandas better, it will be replaced to NaN:

def missing_values_change(val):
    if str(val)=='9' or str(val)=='-1' or str(val)=="Unknown" or str(val)=='99':
        return np.nan
    else:
        return val
for col in dfvehicle.columns:
    dfvehicle[col] = dfvehicle[col].apply(lambda x:missing_values_change(x))

# Checking missing values percentage

dfvehicle.isnull().mean()*100

dfvehicle.isnull().sum().sum()

# Replace missing values using mean and mode

dfvehicle["vehicle_type"].replace(np.NaN,dfvehicle["vehicle_type"].mean(),inplace=True)
dfvehicle["towing_and_articulation"].replace(np.NaN,dfvehicle["towing_and_articulation"].mean(),inplace=True)
dfvehicle["vehicle_manoeuvre"].replace(np.NaN,dfvehicle["vehicle_manoeuvre"].mean(),inplace=True)
dfvehicle["vehicle_location_restricted_lane"].replace(np.NaN,dfvehicle["vehicle_location_restricted_lane"].mean(),inplace=True)
dfvehicle["junction_location"].replace(np.NaN,dfvehicle["junction_location"].mean(),inplace=True)
dfvehicle["skidding_and_overturning"].replace(np.NaN,dfvehicle["skidding_and_overturning"].mean(),inplace=True)
dfvehicle["hit_object_in_carriageway"].replace(np.NaN,dfvehicle["hit_object_in_carriageway"].mean(),inplace=True)
dfvehicle["vehicle_leaving_carriageway"].replace(np.NaN,dfvehicle["vehicle_leaving_carriageway"].mean(),inplace=True)
dfvehicle["vehicle_left_hand_drive"].replace(np.NaN,dfvehicle["vehicle_left_hand_drive"].mean(),inplace=True)
dfvehicle["journey_purpose_of_driver"].replace(np.NaN,dfvehicle["journey_purpose_of_driver"].mean(),inplace=True)
dfvehicle["sex_of_driver"].replace(np.NaN,dfvehicle["sex_of_driver"].mean(),inplace=True)
dfvehicle["hit_object_off_carriageway"].replace(np.NaN,dfvehicle["hit_object_off_carriageway"].mean(),inplace=True)
dfvehicle["age_of_driver"].replace(np.NaN,dfvehicle["age_of_driver"].mean(),inplace=True)
dfvehicle["age_band_of_driver"].replace(np.NaN,dfvehicle["age_band_of_driver"].mean(),inplace=True)
dfvehicle["engine_capacity_cc"].replace(np.NaN,dfvehicle["engine_capacity_cc"].mean(),inplace=True)
dfvehicle["propulsion_code"].replace(np.NaN,dfvehicle["propulsion_code"].mean(),inplace=True)
dfvehicle["age_of_vehicle"].replace(np.NaN,dfvehicle["age_of_vehicle"].mean(),inplace=True)
dfvehicle["generic_make_model"].replace(np.NaN,dfvehicle["generic_make_model"].mode()[0],inplace=True)
dfvehicle["driver_imd_decile"].replace(np.NaN,dfvehicle["driver_imd_decile"].mean(),inplace=True)

dfvehicle.isnull().mean()*100

"""# **Feature Engineering**"""

# Here split the date into day and month and remove the minute from the time
# Created 3 new columns as Hour, Day, and Month.
# Removed columns time and date

# Splitting Time into Hours
dfaccident['Hour']=dfaccident['time'].str.split(':').str[0]

# Splitting Date into days and months
dfaccident['Day']=dfaccident['date'].str.split('/').str[0]
dfaccident['Month']=dfaccident['date'].str.split('/').str[1]

# Converting Hour, Day, Month column type to integer
dfaccident['Hour']=dfaccident['Hour'].astype(int)
dfaccident['Day']=dfaccident['Day'].astype(int)
dfaccident['Month']=dfaccident['Month'].astype(int)

# Drop the Time, Minute and Date columns
dfaccident = dfaccident.drop('time', axis=1)
dfaccident = dfaccident.drop('date', axis=1)

dfaccident

"""# **Descriptive Statistical Analysis**"""

# Descriptive statistics for relevant columns in the Accident daatset

selected_columns = ['number_of_vehicles','number_of_casualties','accident_severity','day_of_week','speed_limit','first_road_class','road_type',
                    'light_conditions','weather_conditions','road_surface_conditions','urban_or_rural_area','Hour','Month','Day']
dfaccident[selected_columns].describe()

# Histogram of all the variables in accident dataset

dfaccident.hist(bins = 10, figsize = (20, 18), color = 'orange', edgecolor = 'black');

# Countplot for target labels

plt.figure(figsize = (2, 4))

ax = sns.countplot(x = dfaccident['accident_severity'], palette='Set1')
ax.bar_label(ax.containers[0])

Label = ['Fatal', 'Serious', 'Slight']

ax.set_xticks(range(len(Label)))
ax.set_xticklabels(Label, rotation=45)

plt.title('Count of Target Labels', fontsize = 12, fontweight = 'bold')
plt.show()

# Pie chart showing distribution of collision severity type

a = dfaccident['accident_severity'].value_counts(normalize=True)
custom_labels = ['Slight', 'Serious', 'Fatal']

plt.figure(figsize=(4,4))
plt.pie(a, autopct='%0.02f%%', labels=custom_labels, explode = (0.06,0,0),colors=['yellowgreen', 'blue','red'], startangle=90)
plt.title('Distribution of Collision Severity', fontsize = 12, fontweight = 'bold')
plt.show()

# Bar chat showing collision by month

plt.figure(figsize = (6, 5))

ax = sns.countplot(x = dfaccident['Month'], palette='Set1')
ax.bar_label(ax.containers[0])

months = ['January', 'February', 'March', 'April', 'May', 'June',
          'July', 'August', 'September', 'October', 'November', 'December']

ax.set_xticks(range(len(months)))
ax.set_xticklabels(months, rotation=45)

plt.title('Collision by Month', fontsize = 12, fontweight = 'bold')
plt.show()

# Bar chat showing collision by days of week

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize = (5, 5))

ax = sns.countplot(x = dfaccident['day_of_week'], palette='Set1')
ax.bar_label(ax.containers[0])

days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',
          'Saturday']

ax.set_xticks(range(len(days)))
ax.set_xticklabels(days, rotation=45)

plt.title('Collision by Days of Week', fontsize = 12, fontweight = 'bold')
plt.show()

# Bar chat showing collision by hours of day

plt.figure(figsize = (12, 5))

ax = sns.countplot(x = dfaccident['Hour'], palette='Set1')
ax.bar_label(ax.containers[0])

plt.title('Collision by Hours of Day', fontsize = 12, fontweight = 'bold')
plt.show()

# Line graph showing Rate of Casualities per Collisions by Speed Limit

sns.lineplot(x='speed_limit', y='number_of_casualties', data=dfaccident)

plt.title('Rate of Casualities per Collisions by Speed Limit', fontsize = 12, fontweight = 'bold')
plt.show()

# Line graph showing fatal Collisions by Speed Limit

# Filter the data to include only fatal accidents
fatal_accidents = dfaccident[dfaccident['accident_severity'] == 1]

# Calculate the number of fatal accidents for each speed limit category
fatal_counts = fatal_accidents['speed_limit'].value_counts().sort_index()

# Create the line plot using seaborn
plt.figure(figsize=(6,5))

sns.lineplot(x=fatal_counts.index, y=fatal_counts.values, marker='o', linestyle='-')

plt.xlabel('Speed Limit')
plt.ylabel('Number of Fatal Collisions')

plt.title('Fatal Collisions by Speed Limit', fontsize = 12, fontweight = 'bold')
plt.show()

unique_values = dfaccident['road_type'].unique()

for value in unique_values:
    print(value)

# Pie chart showing collision rate by road type
# Morethan 70 percentage of the collisions occured in the roundabout

a = dfaccident['road_type'].value_counts(normalize=True)
custom_labels = ['Roundabout','One way street','Dual carriageway','Single carriageway','Slip road','Unknown']

plt.figure(figsize=(4,5,))
plt.pie(a, autopct='%0.02f%%', labels=custom_labels)

plt.title('Rate of Collisions by Road Type', fontsize = 12, fontweight = 'bold')
plt.show()

dfaccident.columns

# Pie chart showing collision rate by firt road class
# Around 80 percentage of the collisions happened in the motorway and motorway standard roads(A(M)).

a = dfaccident['first_road_class'].value_counts(normalize=True)
custom_labels = ['Motorway', 'A(M)', 'A','B','C','Unknown']

plt.figure(figsize=(4,5,))
plt.pie(a, autopct='%0.02f%%', labels=custom_labels)

plt.title('Rate of Collisions by Road Class', fontsize = 12, fontweight = 'bold')
plt.show()

# Pie chart showing number of collisions by region

a = dfaccident['urban_or_rural_area'].value_counts(normalize=True)
custom_labels = ['Urban','Rural','Unallocated']

plt.figure(figsize=(4,5))
plt.pie(a, autopct='%0.02f%%', labels=custom_labels)

plt.title('Number of Collisions by Region', fontsize = 12, fontweight = 'bold')
plt.show()

# Bar chat showing collision by road surface conditions

plt.figure(figsize = (7,7))

ax = sns.countplot(x = dfaccident['road_surface_conditions'], palette='Set1')
ax.bar_label(ax.containers[0])

label = ['Dry','Wet','Snow','Frost','Flood']

ax.set_xticks(range(len(label)))
ax.set_xticklabels(label, rotation=45)

plt.title('Collision by Road Surface Condition', fontsize = 12, fontweight = 'bold')
plt.show()

# Bar chat showing collision by weather

plt.figure(figsize = (6, 5))

ax = sns.countplot(x = dfaccident['weather_conditions'], palette='Set1')
ax.bar_label(ax.containers[0])

label = ['Fine','Raining','Snowing','Fine and high winds','Raining and high winds','Snowing and high winds','Fog or mist','Other','Unknown']

ax.set_xticks(range(len(label)))
ax.set_xticklabels(label, rotation=45)

plt.title('Collision by Road Surface Condition', fontsize = 12, fontweight = 'bold')
plt.show()